import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import time
import cv2
import threading
from flask import Flask, Response
from fusion.sensor_wrapper import AudioSensorWrapper, CameraSensorWrapper
from fusion.adaptive_fusion import AdaptiveFusion

# ì „ì—­ ë³€ìˆ˜
latest_frame = None
latest_result = None
frame_lock = threading.Lock()

app = Flask(__name__)


def audio_loop():
    """ìŒí–¥ ì„¼ì„œ ì „ìš© ë£¨í”„ (ë³„ë„ ìŠ¤ë ˆë“œ)"""
    global latest_result

    audio_sensor = AudioSensorWrapper()
    print("âœ… ìŒí–¥ ì„¼ì„œ ì‹œì‘")

    while True:
        try:
            audio_data = audio_sensor.get_audio_data()

            if audio_data:
                with frame_lock:
                    if latest_result:
                        latest_result['audio'] = audio_data
        except Exception as e:
            print(f"ìŒí–¥ ì˜¤ë¥˜: {e}")
            time.sleep(0.1)


def camera_loop():
    """ì¹´ë©”ë¼ ì„¼ì„œ ì „ìš© ë£¨í”„ (ë©”ì¸ ìŠ¤ë ˆë“œ)"""
    global latest_frame, latest_result

    print("ğŸš€ ì¹´ë©”ë¼ ì‹œìŠ¤í…œ ì‹œì‘\n")

    camera_sensor = CameraSensorWrapper(
        stream_url="http://172.20.10.6:8080/?action=stream"
    )
    fusion = AdaptiveFusion()

    print("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ\n")

    frame_count = 0
    yolo_interval = 3  # YOLOëŠ” 3í”„ë ˆì„ë§ˆë‹¤ë§Œ ì‹¤í–‰
    last_gaps = []
    last_debug = None

    try:
        while True:
            frame_count += 1

            # === í”„ë ˆì„ ì½ê¸° (ë¹ ë¦„!) ===
            ret, frame = camera_sensor.cap.read()
            if not ret:
                time.sleep(0.01)
                continue

            # === YOLOëŠ” Ní”„ë ˆì„ë§ˆë‹¤ë§Œ (ëŠë¦¼ ë°©ì§€) ===
            if frame_count % yolo_interval == 0:
                gaps, _, debug_info = camera_sensor.get_gaps_with_angles()
                if gaps:
                    last_gaps = gaps
                    last_debug = debug_info

            # === ìœµí•© (ìµœì‹  ë°ì´í„°) ===
            result_data = {
                'audio': None,
                'gaps': last_gaps,
                'result': None
            }

            with frame_lock:
                if latest_result and latest_result.get('audio'):
                    result_data['audio'] = latest_result['audio']

            # ìœµí•© ì‹¤í–‰
            if result_data['audio'] and last_gaps:
                try:
                    result_data['result'] = fusion.fuse(
                        result_data['audio'],
                        last_gaps
                    )
                except:
                    pass

            # === ì‹œê°í™” (ë¹ ë¦„!) ===
            vis_frame = visualize_fast(
                frame,
                last_gaps,
                result_data['result'],
                result_data['audio'],
                last_debug
            )

            # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
            with frame_lock:
                latest_frame = vis_frame
                latest_result = result_data

            # === ì§§ì€ ëŒ€ê¸°ë§Œ! ===
            time.sleep(0.01)  # 0.3ì´ˆ â†’ 0.01ì´ˆ (100 FPS ê°€ëŠ¥)

    except Exception as e:
        print(f"\nâŒ ì¹´ë©”ë¼ ì˜¤ë¥˜: {e}")
    finally:
        camera_sensor.cap.release()
        print("\nâ¹ï¸  ì¹´ë©”ë¼ ë£¨í”„ ì¢…ë£Œ")


def visualize_fast(frame, gaps, result, audio_data, debug_info):
    """ìµœì í™”ëœ ì‹œê°í™” (ê°„ë‹¨í•˜ê²Œ!)"""
    vis = frame.copy()
    h, w, _ = vis.shape

    roi_top = debug_info['roi_top'] if debug_info else int(h * 0.6)
    roi_bottom = h
    # === 1. í‹ˆ ì‹œê°í™” ===
    if gaps:
        overlay = vis.copy()

        for i, gap in enumerate(gaps):
            is_best = (result and gap == result['best_gap'])

            if is_best:
                color = (0, 255, 0)      # ì´ˆë¡
                thickness = 6
            elif i == 1:
                color = (0, 165, 255)    # ì£¼í™©
                thickness = 4
            else:
                color = (255, 200, 0)    # í•˜ëŠ˜ìƒ‰
                thickness = 2

            # ì±„ìš°ê¸°
            cv2.rectangle(overlay,
                         (int(gap['start']), roi_top),
                         (int(gap['end']), roi_bottom),
                         color, -1)

            # í…Œë‘ë¦¬
            cv2.rectangle(vis,
                         (int(gap['start']), roi_top),
                         (int(gap['end']), roi_bottom),
                         color, thickness)

            # ìˆœìœ„ ë²ˆí˜¸
            rank_text = f"#{i+1}"
            cv2.putText(vis, rank_text,
                       (int(gap['center']) - 20, roi_top - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 3)

        # ë°˜íˆ¬ëª… íš¨ê³¼
        vis = cv2.addWeighted(vis, 0.5, overlay, 0.5, 0)

    # === 2. ROI ê²½ê³„ì„  ===
    cv2.line(vis, (0, roi_top), (w, roi_top), (0, 255, 255), 2)
    cv2.putText(vis, "ROI", (10, roi_top - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

    # === 3. ìƒíƒœ ì •ë³´ ===
    cv2.rectangle(vis, (5, 5), (450, 100), (0, 0, 0), -1)
    cv2.rectangle(vis, (5, 5), (450, 100), (255, 255, 255), 2)

    if gaps:
        best_gap = result['best_gap'] if result else gaps[0]
        gap_text = f"Best: {best_gap['angle']:+.1f}deg ({best_gap['width']:.0f}px)"
        cv2.putText(vis, gap_text, (15, 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    else:
        cv2.putText(vis, "NO GAP DETECTED", (15, 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    if audio_data:
        mode = result['mode'] if result else "N/A"
        mode_text = "AUDIO" if mode == 'audio_trust' else "VISUAL"
        audio_text = f"{mode_text} | {audio_data['angle']:+.1f}deg | SNR:{audio_data['snr']:.1f}dB"
        color = (0, 255, 0) if audio_data['snr'] > 10 else (0, 165, 255)
        cv2.putText(vis, audio_text, (15, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
    else:
        cv2.putText(vis, "No Audio", (15, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)

    return vis

def generate_frames():
    """MJPEG ìŠ¤íŠ¸ë¦¬ë° (ìµœì í™”)"""
    while True:
        with frame_lock:
            if latest_frame is None:
                time.sleep(0.01)
                continue
            frame = latest_frame.copy()

        # JPEG ì¸ì½”ë”© (í’ˆì§ˆ ë‚®ì¶°ì„œ ì†ë„ UP)
        encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), 70]
        ret, buffer = cv2.imencode('.jpg', frame, encode_param)

        if not ret:
            continue

        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

        time.sleep(0.02)  # 50 FPS


@app.route('/')
def index():
    return """
    <html>
    <head>
        <title>RC Car Vision - Fast</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style>
            body {
                margin: 0;
                padding: 10px;
                background: #000;
                color: #0f0;
                font-family: monospace;
                text-align: center;
            }
            h1 {
                font-size: 1.5em;
                margin: 10px 0;
            }
            img {
                width: 100%;
                max-width: 1280px;
                border: 2px solid #0f0;
            }
            .info {
                font-size: 0.9em;
                margin-top: 10px;
                color: #888;
            }
        </style>
    </head>
    <body>
        <h1>ğŸš— RC CAR - LIVE</h1>
        <img src="/video_feed" alt="Live">
        <div class="info">
            âœ… ì´ˆë¡=1ìˆœìœ„ | âšª íšŒìƒ‰=ê¸°íƒ€ | ğŸ”Š AUD>15dB | ğŸ‘ï¸ VIS<15dB
        </div>
    </body>
    </html>
    """


@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(),
                   mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == "__main__":
    # ìŒí–¥ ì„¼ì„œ ë³„ë„ ìŠ¤ë ˆë“œ
    audio_thread = threading.Thread(target=audio_loop, daemon=True)
    audio_thread.start()
    time.sleep(2)  # ì„¼ì„œ ì´ˆê¸°í™” ëŒ€ê¸°

    # ì¹´ë©”ë¼ ë£¨í”„ ë³„ë„ ìŠ¤ë ˆë“œ
    camera_thread = threading.Thread(target=camera_loop, daemon=True)
    camera_thread.start()
    time.sleep(2)

    # Flask ì„œë²„ ì‹œì‘
    print("\n" + "=" * 60)
    print("ğŸŒ ê³ ì† ì›¹ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„!")
    print("=" * 60)
    print("\nğŸ“º http://172.20.10.6:5000")
    print("\nğŸš€ ìµœì í™”:")
    print("   â€¢ ë©€í‹°ìŠ¤ë ˆë”© (ìŒí–¥ | ì¹´ë©”ë¼ ë¶„ë¦¬)")
    print("   â€¢ YOLO 3í”„ë ˆì„ë§ˆë‹¤")
    print("   â€¢ ëŒ€ê¸°ì‹œê°„ ìµœì†Œí™” (0.01ì´ˆ)")
    print("   â€¢ ê°„ì†Œí™”ëœ ì‹œê°í™”")
    print("\nì¢…ë£Œ: Ctrl+C\n")

    app.run(host='0.0.0.0', port=5000, threaded=True, debug=False)
